#!/usr/bin/env python3
"""
ğŸš€ Ultra GPUä¼˜åŒ–çš„KDçŸ¥è¯†è’¸é¦è®­ç»ƒè„šæœ¬
å……åˆ†å‘æŒ¥8ä¸ªA100çš„GPUç®—åŠ›ï¼Œå®ç°æœ€å¤§ååé‡

ä¸»è¦ä¼˜åŒ–ï¼š
1. ğŸ”¥ å¤§å¹…å¢åŠ æ‰¹æ¬¡å¤§å°ï¼ˆå……åˆ†åˆ©ç”¨æ˜¾å­˜ï¼‰
2. âš¡ æ›´æ¿€è¿›çš„æ¢¯åº¦ç´¯ç§¯
3. ğŸ¯ ä¼˜åŒ–GPUåˆ†é…ç­–ç•¥
4. ğŸ“ˆ åŠ¨æ€å­¦ä¹ ç‡è°ƒåº¦
5. ğŸ’¾ æ˜¾å­˜ä¼˜åŒ–æŠ€æœ¯
"""
import os
import sys
import time
from pathlib import Path

# æ·»åŠ srcåˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from distillation.kd import run_kd_pipeline
from utils.common import setup_logging, set_seed, print_gpu_utilization, cleanup_cache
import logging
from rich.console import Console

# wandbé›†æˆ
try:
    import wandb
    WANDB_AVAILABLE = True
except ImportError:
    WANDB_AVAILABLE = False

console = Console()
logger = logging.getLogger(__name__)

def check_eval_config(dataset_size, eval_steps, epochs, batch_size, grad_accum):
    """ç®€å•æ£€æŸ¥eval_stepsæ˜¯å¦åˆç†ï¼Œç»™å‡ºè­¦å‘Šå’Œå»ºè®®"""
    effective_batch = batch_size * grad_accum
    steps_per_epoch = dataset_size // effective_batch
    total_steps = steps_per_epoch * epochs
    
    warnings = []
    
    # ç®€å•è§„åˆ™æ£€æŸ¥
    if eval_steps >= total_steps:
        suggested = max(50, total_steps // 4)
        warnings.append(f"ğŸš¨ eval_steps ({eval_steps}) >= total_steps ({total_steps})! å»ºè®®: {suggested}")
    elif dataset_size < 10000 and eval_steps > 100:
        suggested = 100
        warnings.append(f"âš ï¸ å°æ•°æ®é›† ({dataset_size}) eval_stepså¤ªå¤§ ({eval_steps})ï¼Œå»ºè®®: {suggested}")
    
    if warnings:
        console.print("[yellow]é…ç½®è­¦å‘Š:[/yellow]")
        for warning in warnings:
            console.print(f"  {warning}")
        return suggested
    return eval_steps

def run_ultra_optimized_kd():
    """
    ğŸš€ Ultra GPUä¼˜åŒ–çš„KDè®­ç»ƒ
    ç›®æ ‡ï¼šå……åˆ†åˆ©ç”¨8ä¸ªA100 GPUï¼Œè¾¾åˆ°80%+åˆ©ç”¨ç‡
    """
    
    # ğŸ”¥ Ultraä¼˜åŒ–å‚æ•°
    config = {
        # åŸºç¡€æ¨¡å‹
        "teacher_model": "Qwen/Qwen3-30B-A3B-Instruct-2507",
        "student_model": "Qwen/Qwen3-8B", 
        "train_data": "data/cloud_aiops/cloud_aiops_train_data.jsonl",
        "eval_data": "data/cloud_aiops/cloud_aiops_eval_data.jsonl",
        "output_dir": "outputs/experiment/ultra_optimized_kd",
        "experiment_name": "ultra_kd_8xa100_maxutil",
        
        # ğŸš€ Ultraä¼˜åŒ–çš„æ‰¹æ¬¡å‚æ•° - å……åˆ†åˆ©ç”¨æ˜¾å­˜
        "kd_batch_size": 12,        # ä»4å¢åŠ åˆ°12 (3å€)
        "kd_grad_accum": 16,        # ä»32å‡å°‘åˆ°16ï¼Œæ€»æ‰¹æ¬¡ä¿æŒ192
        "effective_batch_size": 192, # 12 * 16 = 192
        
        # ğŸŒ¡ï¸ çŸ¥è¯†è’¸é¦å‚æ•°
        "temperature": 8.0,
        "alpha": 0.8,
        
        # ğŸ“ åºåˆ—é•¿åº¦ä¼˜åŒ–
        "max_length": 1536,         # ä¿æŒè¾ƒé•¿åºåˆ—
        
        # ğŸ¯ è®­ç»ƒè½®æ¬¡
        "kd_epochs": 3,             # å‡å°‘åˆ°3è½®ï¼Œä½†æ•ˆç‡æ›´é«˜
        
        # ğŸ“Š ç›‘æ§é¢‘ç‡
        "eval_steps": 500,          # æµ‹è¯•è‡ªåŠ¨ä¿®å¤åŠŸèƒ½ (æ•…æ„è®¾å¤ªå¤§)
        "logging_steps": 25,        # æ›´é¢‘ç¹æ—¥å¿—
        "save_steps": 400,          # é€‚ä¸­ä¿å­˜é¢‘ç‡
        
        # ğŸ”§ å­¦ä¹ ç‡ä¼˜åŒ–
        "kd_lr": 2e-4,              # ç¨å¾®æé«˜å­¦ä¹ ç‡
        "warmup_ratio": 0.05,       # å‡å°‘warmupæ—¶é—´
        "lr_scheduler_type": "cosine_with_restarts",
        
        # âš¡ ç¡¬ä»¶ä¼˜åŒ–
        "use_bf16": True,
        "gradient_checkpointing": True,
        "dataloader_num_workers": 16,  # å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹
        
        # ğŸ’¾ æ˜¾å­˜ä¼˜åŒ–
        "max_grad_norm": 1.0,
        "gradient_accumulation_steps": 16,
        
        # ğŸ¯ Early stopping
        "early_stopping_patience": 2,  # æ›´æ¿€è¿›çš„æ—©åœ
        
        # ğŸ–¥ï¸ GPUä¼˜åŒ–é…ç½®
        "use_manual_device_map": True,
        "teacher_device_map": "auto",   # è®©ç³»ç»Ÿæ™ºèƒ½åˆ†é…
        "student_device_map": "auto",
        
        # ğŸ“Š WandBé…ç½®
        "wandb_project": "Ultra_Optimized_KD",
        "wandb_tags": [
            "ultra-optimized", 
            "8xa100-maxutil", 
            "batch-12x16", 
            "temp-8.0",
            "3epochs-efficient"
        ]
    }
    
    console.print(f"ğŸš€ [bold green]Ultra GPUä¼˜åŒ–KDè®­ç»ƒ[/bold green]: {config['experiment_name']}")
    console.print(f"ğŸ“ è¾“å‡ºç›®å½•: {config['output_dir']}")
    
    # ğŸ” æ™ºèƒ½æ£€æŸ¥eval_stepsé…ç½®
    import json
    try:
        with open(config["train_data"]) as f:
            dataset_size = sum(1 for _ in f)
    except:
        dataset_size = 5503  # fallback
    
    suggested_eval_steps = check_eval_config(
        dataset_size, 
        config["eval_steps"], 
        config["kd_epochs"],
        config["kd_batch_size"], 
        config["kd_grad_accum"]
    )
    
    # å¦‚æœå»ºè®®å€¼ä¸åŒï¼Œè‡ªåŠ¨æ›´æ–°
    if suggested_eval_steps != config["eval_steps"]:
        console.print(f"ğŸ”§ [yellow]è‡ªåŠ¨ä¿®å¤: eval_steps {config['eval_steps']} â†’ {suggested_eval_steps}[/yellow]")
        config["eval_steps"] = suggested_eval_steps
    
    console.print("\nğŸ”¥ [bold red]Ultraä¼˜åŒ–é…ç½®[/bold red]:")
    console.print(f"   ğŸ“¦ æ‰¹æ¬¡å¤§å°: [red]{config['kd_batch_size']}[/red] (ä»4å¢åŠ åˆ°12, 3å€æå‡)")
    console.print(f"   ğŸ”„ æ¢¯åº¦ç´¯ç§¯: [red]{config['kd_grad_accum']}[/red] (ä»32å‡å°‘åˆ°16)")
    console.print(f"   ğŸ¯ æœ‰æ•ˆæ‰¹æ¬¡: [red]{config['effective_batch_size']}[/red] (ä¿æŒ192)")
    console.print(f"   ğŸ“ˆ å­¦ä¹ ç‡: [red]{config['kd_lr']}[/red] (æé«˜åˆ°2e-4)")
    console.print(f"   ğŸŒ¡ï¸  è’¸é¦æ¸©åº¦: [red]{config['temperature']}[/red]")
    console.print(f"   ğŸƒâ€â™‚ï¸ æ•°æ®çº¿ç¨‹: [red]{config['dataloader_num_workers']}[/red] (å¢åŠ åˆ°16)")
    console.print(f"   â±ï¸  è¯„ä¼°é¢‘ç‡: æ¯[red]{config['eval_steps']}[/red]æ­¥")
    
    # æ‰“å°GPUçŠ¶æ€
    print_gpu_utilization()
    
    # åˆå§‹åŒ–WandB
    if WANDB_AVAILABLE:
        wandb.init(
            project=config["wandb_project"],
            name=f"{config['experiment_name']}_{time.strftime('%m%d_%H%M')}",
            tags=config["wandb_tags"],
            config=config
        )
        console.print(f"ğŸ“Š wandbå·²åˆå§‹åŒ–: https://wandb.ai/{wandb.run.entity}/{config['wandb_project']}/runs/{wandb.run.id}")
    
    console.print("\nğŸš€ [bold green]å¯åŠ¨Ultraä¼˜åŒ–KDè®­ç»ƒ[/bold green]...")
    console.print("ğŸ’¡ [yellow]ä¼˜åŒ–é‡ç‚¹[/yellow]:")
    console.print("   â€¢ ğŸ”¥ æ‰¹æ¬¡å¤§å°x3ï¼šå……åˆ†åˆ©ç”¨æ˜¾å­˜")
    console.print("   â€¢ âš¡ æ¢¯åº¦ç´¯ç§¯ä¼˜åŒ–ï¼šå‡å°‘åŒæ­¥å¼€é”€")
    console.print("   â€¢ ğŸ¯ æ›´é«˜å­¦ä¹ ç‡ï¼šåŠ é€Ÿæ”¶æ•›") 
    console.print("   â€¢ ğŸ’¾ æ˜¾å­˜ä¼˜åŒ–ï¼šbf16 + gradient checkpointing")
    console.print("   â€¢ ğŸƒâ€â™‚ï¸ å¤šçº¿ç¨‹æ•°æ®åŠ è½½ï¼šå‡å°‘IOç­‰å¾…")
    
    try:
        result = run_kd_pipeline(
            teacher_model_path=config["teacher_model"],
            student_model_path=config["student_model"],
            train_data_path=config["train_data"],
            eval_data_path=config["eval_data"],
            output_dir=config["output_dir"],
            experiment_name=config["experiment_name"],
            
            # KDè®­ç»ƒå‚æ•°
            kd_epochs=config["kd_epochs"],
            kd_batch_size=config["kd_batch_size"],
            kd_lr=config["kd_lr"],
            kd_grad_accum=config["kd_grad_accum"],
            
            # è’¸é¦å‚æ•°
            temperature=config["temperature"],
            alpha=config["alpha"],
            
            # åºåˆ—é•¿åº¦
            max_length=config["max_length"],
            
            # è¯„ä¼°å‚æ•°
            eval_steps=config["eval_steps"],
            logging_steps=config["logging_steps"],
            save_steps=config["save_steps"],
            
            # å­¦ä¹ ç‡è°ƒåº¦
            warmup_ratio=config["warmup_ratio"],
            lr_scheduler_type=config["lr_scheduler_type"],
            
            # æ—©åœ
            early_stopping_patience=config["early_stopping_patience"],
            
            # ç¡¬ä»¶ä¼˜åŒ–
            use_bf16=config["use_bf16"],
            gradient_checkpointing=config["gradient_checkpointing"],
            dataloader_num_workers=config["dataloader_num_workers"],
            
            # GPUåˆ†é…ä¼˜åŒ–
            use_manual_device_map=config["use_manual_device_map"],
            teacher_device_map=config["teacher_device_map"],
            student_device_map=config["student_device_map"],
            
            # WandB
            use_wandb=WANDB_AVAILABLE,
            wandb_project=config["wandb_project"],
            wandb_tags=config["wandb_tags"]
        )
        
        console.print(f"\nâœ… [bold green]Ultraä¼˜åŒ–KDè®­ç»ƒå®Œæˆï¼[/bold green]")
        
        # æ˜¾ç¤ºç»“æœ
        if "execution_time" in result:
            total_time = result["execution_time"]
            console.print(f"â±ï¸  è®­ç»ƒæ—¶é—´: [green]{total_time:.1f}ç§’[/green] ({total_time/3600:.1f}å°æ—¶)")
            
        if "final_loss" in result:
            final_loss = result["final_loss"]
            console.print(f"ğŸ“‰ æœ€ç»ˆLoss: [green]{final_loss:.4f}[/green]")
        
        # GPUåˆ©ç”¨ç‡ç»Ÿè®¡
        print_gpu_utilization()
        
        return result
        
    except KeyboardInterrupt:
        console.print("\nâš ï¸ [yellow]è®­ç»ƒè¢«ä¸­æ–­[/yellow]")
        cleanup_cache()
        return {"status": "interrupted"}
    except Exception as e:
        console.print(f"\nâŒ [red]è®­ç»ƒå¤±è´¥[/red]: {str(e)}")
        cleanup_cache()
        raise e
    finally:
        if WANDB_AVAILABLE:
            wandb.finish()

if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    set_seed(42)
    setup_logging(level=logging.INFO)
    
    console.print("ğŸ¯ [bold blue]Ultra GPUä¼˜åŒ–KDè®­ç»ƒå¯åŠ¨[/bold blue]")
    
    try:
        result = run_ultra_optimized_kd()
        console.print(f"\nğŸ‰ [bold green]Ultraä¼˜åŒ–è®­ç»ƒæˆåŠŸå®Œæˆï¼[/bold green]")
    except Exception as e:
        console.print(f"\nâŒ [red]è®­ç»ƒå¤±è´¥[/red]: {str(e)}")
        logger.exception("è®­ç»ƒå¼‚å¸¸")
        exit(1)